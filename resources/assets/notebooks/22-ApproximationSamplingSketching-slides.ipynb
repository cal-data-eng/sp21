{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Approximation: Sampling and Sketching\n",
    "1. Pros and Cons of approximation\n",
    "1. Sampling: Reservoir\n",
    "1. Materialized Samples\n",
    "1. Sketching: CountMin and HyperLogLog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pros of Approximation\n",
    "- Fast at \"query time\"\n",
    "- \"Speed of thought\" exploration\n",
    "- HCI literature on latency [Liu, Heer 2014](https://idl.cs.washington.edu/files/2014-Latency-InfoVis.pdf)\n",
    "  <img src=\"files/latencies.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cons of Approximation\n",
    "- Inaccuracies\n",
    "    - Especially missing data from low-frequency phenomena!\n",
    "- Accidental Bias\n",
    "- Quantifying Uncertainty \n",
    "    - Can be hard to do, statistically, for many queries\n",
    "    - Can be hard for humans to interpret even when accurate\n",
    "      - Esp. when combined with visualization! (?)\n",
    "- Sketches have setup (materialization) costs\n",
    "- Others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Approximate, then Scale\n",
    "For exploratory work on very large data sets *we often need to approximate*. Then scale up to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Revisiting Database Sampling\n",
    "- It can be efficient to sample as close to the data as we can\n",
    "- Selection pushdown: \n",
    "  - as little data through your \"pipelines\" as possible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problems with Database Sampling\n",
    "1. Not all data sources support sampling\n",
    "2. The sampling they do support is often very simple: Bernoulli or worse\n",
    "  - Recall Bernoulli: flip a coin per record\n",
    "  - Hard to know the right Bernoulli probability to set for queries\n",
    "  - Bernoulli doesn't let us control output size\n",
    "  - Bernoulli doesn't easily support stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## More Flexible Sampling\n",
    "Is there a simple sampling scheme we could write as a User-Defined Function?\n",
    "  - We can manually  \"push it down\" into a CTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reservoir Sampling: Idea\n",
    "- Suppose you want a sample of size $k$. \n",
    "- Build a \"reservoir\" (fixed array) that holds $k$ records\n",
    "- Scan the table:\n",
    "  - First $k$ records go in the reservoir\n",
    "  - Subsequent records $r_i$ \"evict\" a random record from reservoir\n",
    "    - With some probability $P_i$ based on their scan order $i$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Making Reservoir Sampling \"fair\" (iid)\n",
    "- [independent and identically distributed](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)\n",
    "- Need *equal* probability for every tuple \"lasting\" in the sample $S_n$ at step $n$\n",
    "  - $P(r_i \\in S_n) = P(\\mbox{chosen at step $i$ AND not replaced in later steps})$\n",
    "  -  $= P_i \\cdot \\Pi_{j=i}^n(1 - P_j / k)$\n",
    "  - Consider: $P_i = k/i$.\n",
    "      - E.g. choose a random number $r \\ in [0,i-1]$\n",
    "      - if $(r < k)$ then replace the $r$'th item in the reservoir, else skip\n",
    "- We'll prove the result has equal probability for each tuple!\n",
    "- But first, the code: *so simple*!\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ported from https://en.wikipedia.org/wiki/Reservoir_sampling\n",
    "from random import randrange\n",
    "\n",
    "def reservoirSample(data, n, k):\n",
    "  # fill the reservoir array\n",
    "  r = []\n",
    "  for i in range(k):\n",
    "    r.append(data[i])\n",
    "\n",
    "  # replace elements with gradually decreasing probability\n",
    "  for i in range(k, n-1):\n",
    "    # randrange(a) generates a uniform integer between 0 and a-1\n",
    "    j = randrange(i+1)\n",
    "    if j < k:\n",
    "        r[j] = data[i]\n",
    "            \n",
    "  return(r)\n",
    "     \n",
    "data = list(range(1000))\n",
    "n = len(data)\n",
    "k = 5\n",
    "r = reservoirSample(data, n, k)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Efficiency Discussion\n",
    "When would you want to do reservoir sampling in a data pipeline or database query?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Proof of Correctness\n",
    "By induction.\n",
    "\n",
    "**Base case**: the algorithm works for $n < k$ (probability is 1 for each element)\n",
    "\n",
    "\n",
    "**Induction**: For a reservoir of size $k$ over $n$ elements, assume elements chosen with equal probability\n",
    "We run our algorithm on the $n+1$st element. Need to prove that the resulting reservoir has each of the $n+1$ elements chosen with equal probability!\n",
    "\n",
    "- Consider an earlier element $d_j$, $j < n$, that survives in the reservoir after this step\n",
    "- Two cases how $d_j$ could survive:\n",
    "    1. **skipped $d_{n+1}$:** \n",
    "      - Probability $(1 - k/(n+1))$. \n",
    "      - = $(n + 1 - k) / (n + 1)$.\n",
    "    2. chose $d_{n+1}$, but **replaced another** element: \n",
    "      - Joint probability of \"choose\" and \"replace another\" is $k/(n+1) * (k-1)/k$. \n",
    "      - = $(k-1)/(n+1)$.\n",
    "- Together, the probability of $d_j$ surviving this step is the *sum* (OR) of these cases' probabilities:\n",
    "  - $P(\\mbox{$d_j$ survived the $n+1^{\\mbox{st}}$ step}) = P(\\mbox{skipped}) + P(\\mbox{replaced another})$\n",
    "  - = $((n + 1 - k) / (n + 1)) + (k-1)/(n+1)$ \n",
    "  - = $n/(n+1)$.\n",
    "- By induction $d_j$ was in the reservoir before this step is:\n",
    "  - $P(\\mbox{$d_j$ survived $n$ steps}) = k/n$.\n",
    "  - That was independent of the probability of surviving this step!\n",
    "- So the probability of $d_j$ having survived the prior steps AND this step is the *product*:\n",
    "  - $P(\\mbox{$d_j$ survived $n$ steps}) * P(\\mbox{$d_j$ survived the $n+1^{\\mbox{st}}$ step})$\n",
    "  - $n/(n+1) * k/n = k/(n+1)$\n",
    "  - Aha! Each item that survived is as likely as the new item surviving! Q.E.D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization to Reservoir: AlgorithmL\n",
    "- Calling the random number generator for every row can be slow.\n",
    "- Idea: after each row we choose, could we predict how many rows we'll skip?\n",
    "- Let's plot the gaps between chosen values empirically! (The *sampling gap distribution*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_gaps(r):\n",
    "    r.sort()\n",
    "    gaps = pd.Series(np.diff(r))\n",
    "    gaps.plot.hist(grid=True, bins=20, rwidth=0.9,\n",
    "                   color='#607c8e')\n",
    "data = list(range(100000))\n",
    "n = len(data)\n",
    "k = 1000\n",
    "r = reservoirSample(data, n, k)\n",
    "plot_gaps(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Turns out this is approximately a geometric distribution with a closed form!\n",
    "  - Won't prove here\n",
    "- So we can pick random gaps from geometric distribution\n",
    "  - \"skip over\" the to-be-discarded inputs in between\n",
    "  - only call RNG as many times as there are gaps!\n",
    "  - i.e. about as many times as the size of the sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is called Algorithm L\n",
    "# ported from https://en.wikipedia.org/wiki/Reservoir_sampling\n",
    "from random import random, randrange\n",
    "from math import exp, log, floor\n",
    "\n",
    "def reservoirSampleL(data, n, k):\n",
    "  # fill the reservoir array\n",
    "  r = []\n",
    "  for i in range(k):\n",
    "    r.append(data[i])\n",
    "    \n",
    "  # random.random() generates a uniform [0,1) random number\n",
    "  w = exp(log(random())/k)\n",
    "\n",
    "  while i < n:\n",
    "      i = i + floor(log(random())/log(1-w)) + 1\n",
    "      if i < n:\n",
    "          # replace a random item of the reservoir with item i\n",
    "          r[randrange(k)] = data[i]  # random index between 0 and k-1, inclusive\n",
    "          w = w * exp(log(random())/k)\n",
    "            \n",
    "  return(r)\n",
    "     \n",
    "data = list(range(1000))\n",
    "n = len(data)\n",
    "k = 5\n",
    "r = reservoirSampleL(data, n, k)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(range(100000))\n",
    "n = len(data)\n",
    "k = 1000\n",
    "r = reservoirSampleL(data, n, k)\n",
    "plot_gaps(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reservoir Sampling as a Table-Valued UDF in PostgreSQL\n",
    "We can implement a reservoir as a table function that returns (rownumber, pos) pairs and join with that to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace the database connection with a database of your own!\n",
    "%reload_ext sql\n",
    "%sql postgresql://jmh@localhost:5432/baseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TYPE IF EXISTS reservoir_pair CASCADE;\n",
    "CREATE TYPE reservoir_pair AS (rownum integer, pos integer);\n",
    "CREATE OR REPLACE FUNCTION reservoir_swaps(k integer, n integer) RETURNS setof reservoir_pair\n",
    "    AS $$\n",
    "\n",
    "  from random import random, randrange\n",
    "  from math import exp, log, floor\n",
    "  # fill the reservoir array\n",
    "  r = []\n",
    "\n",
    "  for i in range(k):\n",
    "    yield((i,i))\n",
    "    \n",
    "  # random.random() generates a uniform [0,1) random number\n",
    "  w = exp(log(random())/k)\n",
    "\n",
    "  while i < n:\n",
    "      i = i + floor(log(random())/log(1-w)) + 1\n",
    "      if i < n:\n",
    "          # replace a random item of the reservoir with item i\n",
    "          w = w * exp(log(random())/k)\n",
    "          yield(i, randrange(k))  # random index between 0 and k-1, inclusive\n",
    "            \n",
    "  return(r)\n",
    "    $$\n",
    "    LANGUAGE 'plpython3u'\n",
    "    VOLATILE\n",
    "    RETURNS NULL ON NULL INPUT;\n",
    "CREATE OR REPLACE FUNCTION reservoir_rows(k integer, n integer) RETURNS setof integer\n",
    "  AS $$ SELECT MAX(rownum) AS rownum FROM reservoir_swaps(k, n) GROUP by pos $$ \n",
    "LANGUAGE 'sql'\n",
    "VOLATILE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH rrows AS (SELECT reservoir_rows(10, count(*)::integer) AS rows \n",
    "                 FROM batting),\n",
    "     rbatting AS (SELECT row_number() over(), * \n",
    "                    FROM batting)\n",
    "SELECT *\n",
    "  FROM rbatting, rrows \n",
    " WHERE row_number = rows;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stratified Sampling\n",
    "We often want to do what's called *stratified sampling*.\n",
    "\n",
    "- SQL folks might call it GROUP BY sampling\n",
    "  - i.e. I want a $k$-sized sample per GROUP\n",
    "  - the \"GROUP BY\" columns are called \"subpopulations\"\n",
    "- PostgreSQL's Bernoulli tablesamples do not support stratification\n",
    "  - the sample happens on the initial scan\n",
    "- But our reservoir implementation works with GROUP BY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Stratified Sampling with Reservoirs\n",
    "WITH grprows AS (SELECT teamid, reservoir_rows(10, COUNT(*)::integer) AS rows \n",
    "                   FROM batting \n",
    "                  GROUP BY teamid),\n",
    "     rbatting AS (SELECT row_number() over(partition by teamid), * \n",
    "                    FROM batting)\n",
    "SELECT *\n",
    "  FROM rbatting b, grprows g\n",
    " WHERE row_number = rows\n",
    "   AND b.teamid = g.teamid\n",
    " ORDER BY b.teamid;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Materialized Samples\n",
    "- We can use `CREATE TABLE AS SELECT ...` to put a sample into a table. \n",
    "- Then we can reuse the sample at will\n",
    "  - E.g. load it onto our desktop and even use Pandas instead of SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Concerns with Materialized Samples\n",
    "1. Be sure to normalize estimators appropriately\n",
    "     - e.g. multiply COUNT or SUM by sampling rate\n",
    "2. There will be uncertainty in these estimators\n",
    "     - sometimes stats offers a *confidence interval* on estimators\n",
    "       - e.g. \"with probability $p$ the true value equals the estimate +- $\\epsilon$\"\n",
    "     - depends on the query structure\n",
    "     - Resampling (bootstrap) can give you a sense of the C.I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Concerns with Materialized Samples, Cont.\n",
    "3. If you reuse the sample for many different estimators, you will eventually be biased.\n",
    "     - Resampling from the sample can help\n",
    "     - Periodically refresh the sample from the DB\n",
    "4. You **need to validate on the full dataset**\n",
    "     - After exploratory work, run the pipeline on the full data!\n",
    "     - Best to do your \"desktop\" work in a scalable language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Notes on Samples and SQL\n",
    "Do not join table samples!\n",
    "```SELECT SUM(E.salary / D.budget) \n",
    "    FROM employees E INNER JOIN departments D```\n",
    "- We'd like to estimate this value on $sample(E \\bowtie D)$\n",
    "- *Sad Fact*: $sample(E \\bowtie D) \\ne (sample(E) \\bowtie sample(D)) $!\n",
    "  - TABLESAMPLE with JOIN gives nonsense in the SUM!\n",
    "- *Worse Fact*: the join of two table samples is often empty!! \n",
    "  - Think about odds of an employee's dept being in sample!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Notes on Samples and SQL, cont.\n",
    "- There is research in the area of *Approximate Query Processing*\n",
    "  - not common in shipping database systems.\n",
    "- More complex SQL also messes up sampling/estimators\n",
    "  - Window queries, subqueries, etc.\n",
    "- Pragmatic strategy\n",
    "  1. Play with samples of query outputs as CTEs/Views/CTAS\n",
    "  2. *Don't* do complicated SQL with the sample \n",
    "    - No join, window, subquery, etc.\n",
    "    - Instead do the complicated SQL on the full tables\n",
    "    - Go to (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sketches\n",
    "- Alternative materialization scheme to samples\n",
    "  - Small (KBs!) probabilistic data structures\n",
    "  - Independent of actual data size!\n",
    "- Query estimates with bounded error in log time\n",
    "- Sometimes called \"synopsis data structures\"\n",
    "- Prof. Jelani Nelson is our local expert in CS\n",
    "  - Offers an entire class on sketches!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two Very Useful Sketches\n",
    "  - *CountMin* sketches for `SELECT COUNT(*) ... WHERE col = k`\n",
    "    - Also `WHERE col BETWEEN k AND l`\n",
    "  - *HyperLogLog* sketches for `SELECT COUNT(DISTINCT col)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inuition for CountMin Sketch\n",
    "`SELECT COUNT(*) ... WHERE col = x`\n",
    "\n",
    "Incredibly simple idea!\n",
    "\n",
    "Intuition:\n",
    "- Pick a hash function $h$ that maps the data type of `col` to integers\n",
    "- Create an array $A$ of $b$ counters\n",
    "- For each value $v$ in `col`, increment the counter at $A[{h(v)}]$\n",
    "- To compute the count of rows `WHERE col = x` return $A[{h(x)}]$\n",
    "\n",
    "How bad is our estimate?\n",
    "- Could be *too high*, due to hash \"collisions\" (never too low!)\n",
    "- If we collide with key $y \\ne x$, we return the sum of their frequencies\n",
    "  - $A[{h(x)}] = f_x + \\sum_{y \\in S}f_y \\hspace{2em}$ where $S = {y \\ne x : h_i(y) = h_i(x)}$\n",
    "  - We expect $x$ to collide with $1/b$ of the values in our data\n",
    "  - So we expect $A[{h(x)}] = f_x + \\frac{1}{b}\\sum_{y \\ne x}f_y \\le f_x + \\frac{n}{b}$\n",
    "    - after all, the sum of all frequencies is $n$\n",
    "  - If we want to bound our overestimate by $\\epsilon f_x$, just choose $b = 1/\\epsilon$.\n",
    "  - Note this has no dependence on $n$, the size of our dataset: scales great!\n",
    "  \n",
    "Why not stop here?\n",
    "  - We got the expected error to an $\\epsilon$ factor!\n",
    "  - But the *variance* in the error can be high\n",
    "    - some buckets will be \"unlucky\"!\n",
    "    - We want the probability that the error is bigger than $\\epsilon$ to be $\\delta$.\n",
    "  - So let's use the idea of independent samples to help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CountMin Sketch\n",
    "- Repeat the idea above with $l$ pairwise-independent hash functions.\n",
    "  - Easy to parameterize these from a \"family\"\n",
    "  - The CountMin Sketch is an array of $l$ rows and $b$ columns\n",
    "    - each row \"belongs\" to one of the hash functions\n",
    "<img src=\"files/countMin.png\" height=1in>\n",
    "- Insertion\n",
    "  - For each value $v$ in the input, for each hash function $l$, increment $h_l(v)$\n",
    "- To compute the count of key $x$, look up all $l$ values $h_l(x)$\n",
    "  - Each is an overestimate...\n",
    "  - So return the minimum: $\\min_{i=0}^l A_i[x]$!\n",
    "- With some more work, you can show that we want $l = \\log_2 \\frac{1}{\\delta}$ \n",
    "  - bounds the probability of exceeding $\\epsilon$ at $\\delta$\n",
    "  - google for the math or take Prof. Nelson's class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CountMin Sketches in Practice\n",
    "- Easy to write\n",
    "  - You can find lots of reference implementations online in Java, C++, Python, etc.\n",
    "  - PostgreSQL has a package called [Apache MADLib](https://madlib.apache.org/) that provides [CountMin sketches](http://madlib.apache.org/docs/latest/group__grp__countmin.html) and lots of Stat/ML routines in SQL\n",
    "- Scales to arbitrarily large data sets!\n",
    "- In practice, all the hashing at construction time can be slow\n",
    "  - Needs to be paid off by many queries\n",
    "  - Parallelizes trivially though!\n",
    "  \n",
    "- PostgreSQL/MADlib example below\n",
    "  - [MADlib CMsketch](https://github.com/apache/madlib/blob/4987e8fe5367bb823afb1bd4020fd6f0fa603258/methods/sketch/src/pg_gp/countmin.h) is set to $l = 8, b = 1024$. With 64-bit integers this is just 64 KB!\n",
    "    - $\\epsilon = 2/b = .002$\n",
    "    - $\\delta = \\frac{1}{2}^l = .004$ (i.e., $99.6\\%$ probability within $\\epsilon n$!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MADlib is only compatible with PostgreSQL 12\n",
    "## My PostgreSQL 12 installation didn't have Python3\n",
    "## So let's switch connections now\n",
    "%reload_ext sql\n",
    "%sql postgresql://jmh@localhost:5433/baseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH data AS (SELECT floor(random()*10)::integer AS class, \n",
    "                     floor(exp(log(random()*100)))::integer AS a1 FROM generate_series(1,100000)),\n",
    "     sketch AS (SELECT madlib.cmsketch(class) AS class_cm, madlib.cmsketch(a1) AS a1_cm FROM data)\n",
    "SELECT 'sketch' as method, \n",
    "       madlib.cmsketch_count(class_cm, 7) as class_7, madlib.cmsketch_count(class_cm, 9) as class_9, \n",
    "       madlib.cmsketch_count(a1_cm, 3) as a1_3, madlib.cmsketch_count(a1_cm, 7) as a1_7\n",
    "  FROM sketch\n",
    "UNION ALL\n",
    "SELECT 'actual', \n",
    "       sum(CASE WHEN class = 7 THEN 1 ELSE 0 END), sum(CASE WHEN class = 9 THEN 1 ELSE 0 END),\n",
    "       sum(CASE WHEN a1 = 3 THEN 1 ELSE 0 END), sum(CASE WHEN a1 = 7 THEN 1 ELSE 0 END)\n",
    "  FROM data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH sketch AS (SELECT madlib.cmsketch(hr) AS hr_cm FROM batting)\n",
    "SELECT 'sketch' as method, \n",
    "       madlib.cmsketch_count(hr_cm, 40)\n",
    "  FROM sketch\n",
    "UNION ALL\n",
    "SELECT 'actual', \n",
    "       COUNT(*)\n",
    "  FROM batting\n",
    " WHERE hr = 40;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HyperLogLog Sketch\n",
    "`SELECT COUNT(DISTINCT col) FROM table`\n",
    "\n",
    "Problem:\n",
    "- Imagine you've seen 1 billion distinct values so far\n",
    "  - Originally studied to classify network packet streams at line rate\n",
    "  - How many unique source/destination pairs have we seen?\n",
    "- To see if a new row has a new value, we need to remember the previous 1 billion!\n",
    "- Can we do this in a small amount of space?\n",
    "\n",
    "HyperLogLog is one of many solutions to this problem.\n",
    "- Jelani Nelson is a co-author on [the first asymptotically space- and time-optimal algorithm](https://dash.harvard.edu/bitstream/handle/1/13820438/f0.pdf) for this problem.\n",
    "- Recently [completely resolved the asymptotic space complexity](http://people.eecs.berkeley.edu/~minilek/publications/papers/approx_count.pdf) of this problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## HyperLogLog Intuition\n",
    "- For each value $v$ we see, compute a hash $h(v)$\n",
    "  - Generates a number chosen uniformly at random between 0 and $\\infty$\n",
    "  - How many leading 0's on the left do we expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/number-of-leading-zeros-in-binary-representation-of-a-given-number/\n",
    "def countZeros(x): \n",
    "    # Keep shifting x by one until \n",
    "    # leftmost bit does not become 1.\n",
    "    total_bits = 32\n",
    "    res = 0\n",
    "    while ((x & (1 << (total_bits - 1))) == 0):\n",
    "        x = (x << 1)\n",
    "        res += 1\n",
    "  \n",
    "    return res\n",
    "\n",
    "\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "s = pd.Series([countZeros(hash(i)) for i in range(1,1000)])\n",
    "s.plot.hist(grid=True, bins=20, rwidth=0.9, color='#607c8e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Run the cell above a few times and you'll see:\n",
    "- About 1/2 the values have no leading zeros. Makes sense!\n",
    "    - These are random bit strings, so odds that first bit is `1` is $50\\%$\n",
    "- Decays by a factor of 2 for each bar to the right. Makes sense!\n",
    "    - Odds that the first 2 bits are `10` is $25\\%$. Etc.\n",
    "- Continuing to divide by 2, we expect the rightmost non-zero bar to be at $\\rho = log_2(n) - 1$ \n",
    "  - Where $n$ is the total number of values\n",
    "  - But note: adding *duplicate* values raises all bars but doesn't add any new bars to the right!\n",
    "  - So $2^{\\rho + 1}$ is a good estimator of `COUNT(DISTINCT)`!!\n",
    "- But ... lots of variance across trials.\n",
    "- HyperLogLog breaks the input into subsets and uses the harmonic mean of the resulting estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### HyperLogLog in Practice\n",
    "- With $m$ bytes of memory gives accuracy of $1.04/\\sqrt{m}$\n",
    "  - E.g. $2%$ accuracy with 1.5KB of memory\n",
    "- You can find lots of implementations online\n",
    "- Apache MADlib has an older sketch from the same lead author (P. Flajolet) called an [FM sketch](http://madlib.apache.org/docs/latest/group__grp__fmsketch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH data AS (SELECT floor(random()*10)::integer AS class, \n",
    "                     floor(exp(log(random()*100)))::integer AS a1 FROM generate_series(1,100000)),\n",
    "     approx AS (SELECT madlib.fmsketch_dcount(class) AS class_fm, madlib.fmsketch_dcount(a1) AS a1_fm FROM data)\n",
    "SELECT 'sketch' as method, \n",
    "       *\n",
    "  FROM approx\n",
    "UNION ALL\n",
    "SELECT 'actual', \n",
    "       COUNT(DISTINCT class), COUNT(DISTINCT a1)\n",
    "  FROM data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## More on Sketching\n",
    "Sketches are like materialized views that can approximate the answer to a class of queries.\n",
    "- Like Materialized views, they take time to build, and need to be kept \"fresh\"\n",
    "  - But they're typically *tiny* and insensitive to input size, which is very cool\n",
    "  - Can pass them around for all kinds of tricks: e.g. ship to apps in browser or phone, etc.\n",
    "- Sketches typically work as streaming algorithms, which is nice\n",
    "  - Most support incremental additions\n",
    "  - Some support deletions\n",
    "- Many can be computed in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## More on Sketching, cont.\n",
    "\n",
    "- There are more sketch types and variants to handle more classes of queries\n",
    "  - \"Heavy Hitter\" queries (return the top k most popular values in the stream)\n",
    "  - Exists queries (the earliest sketch: Bloom Filters)\n",
    "  - Count-Range queries\n",
    "  - Histograms\n",
    "  - Approximate data cubes\n",
    "  - Etc.\n",
    "\n",
    "\n",
    "Sketches are mostly used in high-volume streaming settings\n",
    "  - The approximation/performance tradeoffs has to be acceptable\n",
    "  - You need to have a need to do LOTS of queries on the sketch to amortize cost of hashing\n",
    "  - Not typically supported in database systems even today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources\n",
    "- Prof. Nelson's [graduate course at Berkeley](https://www.sketchingbigdata.org/fall20/)\n",
    "- Book: Cormode/Garofalakis/Haas/Jermaine [Synopses for Massive Data: Samples, Histograms, Wavelets, Sketches](https://db.cs.berkeley.edu/cs286/papers/synopses-fntdb2012.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material below is scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- For reference, Reservoir sampling in PL/PGSQL\n",
    "%%sql\n",
    "DROP TYPE IF EXISTS reservoir_pair CASCADE;\n",
    "CREATE TYPE reservoir_pair AS (rownum integer, pos integer);\n",
    "CREATE OR REPLACE FUNCTION reservoir_swaps(integer, integer) RETURNS setof reservoir_pair\n",
    "    AS $$\n",
    "       DECLARE \n",
    "        w float;\n",
    "        k alias for $1;\n",
    "        n alias for $2;\n",
    "        i integer;\n",
    "        retval integer := NULL;\n",
    "       BEGIN\n",
    "       w := exp(log(random())/k::float);\n",
    "            \n",
    "       FOR i IN 0..k LOOP\n",
    "         RETURN NEXT ROW(i, i);\n",
    "       END LOOP;\n",
    "    \n",
    "       i := k;\n",
    "        \n",
    "       WHILE i < n LOOP\n",
    "         i := i + floor(log(random())/log(1-w)) + 1;\n",
    "         IF i < n THEN\n",
    "           w := w * exp(log(random())/k);\n",
    "           RETURN NEXT ROW(i, floor(random()*k)::integer);\n",
    "         END IF;\n",
    "       END LOOP;\n",
    "       END;\n",
    "    $$\n",
    "    LANGUAGE 'plpgsql'\n",
    "    VOLATILE\n",
    "    RETURNS NULL ON NULL INPUT;\n",
    "CREATE OR REPLACE FUNCTION reservoir_rows(k integer, n integer) RETURNS setof integer\n",
    "  AS $$ SELECT MAX(rownum) AS rownum FROM reservoir_swaps(k, n) GROUP by pos $$ \n",
    "LANGUAGE 'sql'\n",
    "VOLATILE;"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
